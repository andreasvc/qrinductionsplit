\documentclass{article}
\usepackage{amsmath}
\usepackage{verbatim}
\usepackage[pdftex]{graphicx}
\usepackage[english]{babel}
\usepackage[colorlinks=true, linkcolor=black, urlcolor=blue, pdfborder={0 0 0}]{hyperref}
%\usepackage{synttree}
%\usepackage[utf8x]{inputenc}

\title{Model Minimization in Qualitative Reasoning}
\author{Andreas van Cranenburgh \\ 0440949 \\ acranenb@science.uva.nl 
\and Hanne Nijhuis \\ 0364568 \\ hnijhuis@science.uva.nl}

\begin{document}
\maketitle

\abstract{Qualitative Process theory provides a way of modeling causality in a
system. Previous work has attempted to automatically induce qualitative models
from behavior. We extend this work by turning monolithic models into minimized,
modular models. The resulting minimization algorithm is general enough to apply
to user generated models as well.}

\newpage

\tableofcontents
\newpage

\section{Introduction}

\section{Literature Review}
In this section we will review a few of the papers that have contributed
greatly to the definition of Qualitative Reasoning. We will give a short
summary of the papers and will conclude with an overview of the current field
of research and possible future work.

\subsection{Qualitative Reasoning}
The following papers describe the foundations of qualitative reasoning.

\subsubsection{A qualitative Physics based on confluences (de Kleer \& Brown)}

\cite{kleer} present a framework for formalizing physics in a qualitative
rather than quantitative manner. Whereas physicists describe the world in terms
of continuous differential equations, the rest of the world uses an implicit
psychological model of naive physics. The framework of \cite{kleer} falls between
these two extremes of precision and informality. Although their framework is completely
qualitative, as opposed to standard physics, on the other hand their framework
is formal in the sense of explicitly defining causal and structural relations, as opposed
to the psychological models of humans (presumably).

This approach is presented as being useful for physics education, expert
systems and even physics, in that it explicitly deals with causality. The
latter is in contrast with standard physics, in which laws are merely
correlations without exceptions.

% more to come.

\subsubsection{Qualitative Process Theory (Forbus)}
Around the same time as de Kleer \& Brown, another approach was introduced by
Forbus \cite{forbus}. The important points that set his work appart were, among
others, the \emph{quantity-spaces} and the \emph{sole mechanism assumption}.

The principle of quantity spaces represents values by a set of ordinal
relationships. This enables the system to easily compare the different
quantities in terms of smaller, equal or larger. If such comparisons would only
occur between two values, then sign values would suffice (-,0,+), but for many
cases, the ordinal representation is more natural.

\vspace{0.8em}

Physical processes are viewed as the mechanisms by which changes occur. Therefor
Forbus introduced the \emph{sole mechanism assumption} which states that any
behavior must be explainable by the direct or indirect effects of some
collection of physical processes.

\vspace{0.8em}

Forbus has reviewed his own work and the impact of his work in \cite{forbus12}.

\subsubsection{Garp3 - Workbench for Qualitative Modelling and Simulation (Bredeweg et al.)}

\subsubsection{Discussion}

The idea that Qualitative Reasoning can formalize common sense knowledge and
understanding of physics is by now outdated. It is an instance of the ``Good
Old Fashioned Artificial Intelligence'' (GOFAI) approach, and in line with the
Symbol System hypothesis of Newell and Simon \cite{newell}.
Both of these have either failed spectucularly or faded silently, having been
replaced by stochastic and data-driven approaches.  Claiming that Qualitative
Reasoning can provide a way to model actual common sense knowledge or mental
models is ostensively wrong -- the list of mismatches with human intuitions is
endless, and among these mismatches are the parts where Folk Physics is
ostensively {\em wrong}. Therefore we submit that it is no longer useful to
present it as a part of Artificial Intelligence or having anything to do with
common sense; while QR models are certainly artificial, they are not in the
least intelligent, nor are they common or do they make sense to non-experts.
They are simply an explicit formalization of a certain set of behaviors of
interest. This does not mean that Qualitative Reasoning itself is a fruitless
enterprise -- it can be used as an educational tool, where there is no need for
bold philosophical claims.

With this educational focus in mind it makes sense to try to facilitate the
modeling process for non-experts for which QR is useful. To this end we turn to
the topic of model induction.

\subsection{Automated Modeling}

To introduce the recent developments in the field of automated modeling we
will now review a few papers on this topic.

\subsubsection{Automated modeling in process-based qualitative reasoning
(Buisman)}
The concept of automated modeling for qualitative process theory was introduced
by Buisman \cite{buisman} in 2007. He motivates the research with the goal to
relieve the strain placed on experts and beginners, and to speed up the
modelling process. The approach he took however, does not attain these
goals yet, but is more of an exploration of the possibilities of using
Artificial Intelligence to induce models based on behavior graphs. We will give
a short overview of the algorithm he developed.

The input for the algorithm consists of:

\begin{itemize}

\item Behavior graph (states and state transitions) of a full envisionment

\item Scenario (partial information about structural relations between entities and their quantities)

\item ISA-hierarchy (full description of entity type hierarchy and quantities)

\end{itemize}

With this input, the algorithm produces models which are ready for simulation.
For each scenario they should give the same output as the original model.

There are certain constraints on the input. The \emph{full envisionment}
requirement means that the behavior is known for all possible initial values for
all quantities in the system. Also, the derivatives and amounts have to be
defined for every state. Finally, the input data cannot contain any noise, 
ie., it should be perfect.

The algorithm starts with searching for so called \emph{naive dependencies},
which are dependencies that are consistent with the entire state-graph. They are
found by applying consistency rules on all pairs of quantities. These
consistency rules consider the amount and derivative values of the quantities
for all states, so as to induce possible dependencies. For example, a positive
influence between $Q_1$ and $Q_2$ could exist if for every state $A_s(Q_1) =
D_s(Q_2)$.  There will be redundancy in the set of naive dependencies which has
to be pruned by filtering out substitutionary groups, which are defined as
mutually exclusive possible disambiguations. 

%HAVE TO REWRITE THIS!!
%testing.. 

\subsubsection{Jochem}
%less brute force, instead attempt to find the conceptually correct model immediately

\subsubsection{Carsten}
Causal groups % feedback loops, interacting processes

\subsection{Overview}
%overview of what?

\section{Theory}

In the field of QR, models %( / scenario's / systems ?) 
consist of
several smaller fragments which can be roughly divided in three categories:
static, process and agent. This categorization is not strict, but gives
a certain view on how things work. Static fragments are used to describe the
structure of a model, as well as proportionalities between quantities. A static
fragment cannot have any agents or influences in it. A \emph{process} fragment
should have at least one direct influence and is not restricted in terms of dependencies. %(relations?)
Finally, \emph{agent} fragments should be used to describe any influences on a
system that are external, hence not part of the system itself.

Fragments can be useful to make the complete system more comprehensible -- ie., they are a form of chunking. 
Also, while building these complex models, fragments allow the user to focus on
what happens in a small part of the model, without having to worry about the
other 'components'. For example in a model describing a population, seperate
fragments could describe processes like birth, death, emigration, etc.

Recent work on automated modeling \cite{buisman, liem, vanweelden} has focused
on generating a correct model based on a full-envisionment behavior graph. The
current algorithms always produce a single model fragment which describes the
complete system. The useful fragmentation of a system is hereby lost and
comprehending the output could become quite difficult with large models. We
therefore introduce a way of splitting such a single monolithic model into
smaller fragments while preserving the exact same behavior.

\section{Approach}
In this section we describe our approach on minimizing, generalizing and
splitting single model fragments into modular and compositional fragments.

\subsection{Problem statement}

We take a monolithic model and divide it into several smaller fragments. To do
so, we need to comply to the following ranked list of constraints:

\begin{enumerate}
\item The model should be equivalent, that is, the resulting behavior should be
	exactly the same as the original

\item The output should be as parsimonious as possible, that is, fragments
	should be modular

\item General fragments are preferred over specific fragments; this entails a
	preference for smaller fragments

\end{enumerate}

\subsection{Algorithm}

Overview:

\begin{itemize}

\item Find a list of pivots, conditions on which the model fragments are based.
	Currently these are single structural relations.

\item For each pivot, find a set of dependencies which apply whenever the pivot
	is present, without exception

\item Generalize these dependencies into a single model fragment, several
	dependencies among instances may be collapsed into one

\end{itemize}

% fragments that can be generalized (ie., relations between quantity classes)
% collapes M into a set of sets containing generalized dependencies.
%
% incorrect definition (todo): fragments = smallest union of all possible sets
% { d | dependency(d) & d = generalized(di) & di in M } such that there is
% exactly one structural relation shared by them.
%
% where dependency is true for dependency triples, and generalized is a
% function that takes a dependency between instances of quantities and returns
% a dependency between the classes of those entities.

Sketch of the algorithm:

\begin{enumerate}

\item Input: take the set of dependencies, $M$, (as generated by eg. model
	induction or from a monolithic model fragment created by a user).  

\item Partition this set into equivalence classes according to the
	equivalence relation of the conditions under which each dependency holds.

\item Minimize each equivalence class by substituting 
	$Q_1 \overset{I+}{\rightarrow} Q_2 $ for a set such as 
	$ \{ Q_1^a \overset{I+}{\rightarrow} Q_2^b, Q_1^c \overset{I+}{\rightarrow} Q_2^d,  . . . \} $, 
	yielding elements of $MFs$

\item Dump the remaining dependencies in a single fragment, $UF$. 
	This set should be empty if the model is properly designed.

\item Output: minimized model $ = MFs \cup \{ UF \} $

\end{enumerate}

This sketch can be formalized into a definition with set builder notation.
First two helper definitions. The first definition defines a predicate for
instances:

\begin{align*}
instance(R, Q_1, Q_2, q_1, q_2) :=
	\; &struct\_rel(R, e_1, e_2) & \\
	\land \; &isa(e_1, E_1) \land isa(e_2, E_2) \\
	\land \; &has(e_1, q_1) \land has(e_2, q_2)  \\
	\land \; &isa(q_1, Q_1) \land isa(q_2, Q_2) \\
\end{align*}

The next definition defines an equivalence relation on these instances, stating that
their dependencies hold universally given their condition (which is currently
restricted to a single structural relation):

\begin{align*}
samedeps(R, Q_1, Q_2) := \; \forall d \; [ \; &dependency(d, q_1, q_2) \in M \\
	& 	\rightarrow \forall e^\prime_1, e^\prime_2 \; [ \; ( isa(e^\prime_1, E_1) \land isa(e^\prime_2, E_2)  \\
	&	\quad 	\land struct\_rel(r, e^\prime_1, e^\prime_2)  \\
	&	\quad 	\land has(e^\prime_1, q^\prime_1) \land has(e^\prime_2, q^\prime_2) ) \\
	& \qquad \rightarrow dependency(d, q^\prime_1, q^\prime_2) \in M \; ] \; ]
\end{align*}

These two conditions combined gives us the set of pivots for a given monolithic model:

\begin{align*}
pivots := \{ \; \langle R, Q_1, Q_2 \rangle \; | instance(R, Q_1, Q_2, q_1, q_2) \land samedeps(R, Q_1, Q_2) \} 
\end{align*}

After defining the pivots we simply map them to dependencies to obtain generalized fragments:

\begin{align*}
fragments := \{ \; \{ \; dependency&(d, Q_1, Q_2) \; | \; \\
		& dependency(d, q_1, q_2)  \in M \\
		\land \; & isa(q_1, Q_1)  \land isa(q_2, Q_2) \; \} \\
	\; | \; \langle R, Q_1, Q_2 \rangle &\in pivots \; \}
\end{align*}

Note that while in this definiton pivots are restricted to single triples of a
relation and two quantities, the definition should be generalized so that
pivots can consist of multiple triples.

\section{Experiments \& Results}

The evaluation is based on a few well known example Garp models. The output of
the automatic modelling implementations of \cite{buisman} and \cite{vanweelden}
is not easily accessible in a single prolog list, but rather through a poorly
documented Prolog database; the current implementation of \cite{vanweelden}
does not return equalities and arithmetic relations among its output. The
scenario and entity hierarchy is accessible through the Garp API, but this is
also less straightforward than it should be. 

To avoid having to deal with these implementation matters we have based our
current implementation on our own Prolog representation. Our implementation
expects as its input a simple list of dependencies, and as background knowledge
the scenario and entity hierarchy. Because of this evaluation had to be done
manually.

The implementation of the algorithm previously described has certain
limitations which mean that the number of fragments is not as minimal as it
could be. This boils down to:

\begin{itemize}

\item not considering other conditions than structural relations as pivots

\item not considering multiple conditions for a single fragment

\item not considering merging the dependencies of multiple quantities belonging
	to the same entity in a single fragment

\end{itemize}

However, this seems to be largely an implemantion aspect. The implementation
provides a proof of concept of the algorithm, more sophisticated
implementations can easily achieve more results.

\subsection{Evaluated Models}

% paste some output here, take screenshots or save EPS files from Garp3
% todo: visual representation of results; either in Garp or Dia diagrams
% 	(whichever is least work).

\subsubsection{Tree and shade growth} 
% maybe show scenario with three trees, number of model fragments should stay the same! proof of concept.

\begin{verbatim}
Input: 
[dependency(inf_pos, growth_rate1, size1), 
dependency(prop_pos, size1,growth_rate1), 
dependency(prop_pos, size1, shade1),
dependency(q_correspondence, size1, shade1), 
dependency(q_correspondence, shade1, size1)]

Set of struct rels: 
[ (self, size, size), (self, shade, size), (self, shade, shade), 
(self, growth_rate, size), (self, growth_rate, shade), 
(self, growth_rate, growth_rate)]

Fragments (2): 
[ (self, shade, size), 
	dependency(prop_pos, size, shade),
	dependency(q_correspondence, size, shade), 
	dependency(q_correspondence, shade, size)] 
[ (self, growth_rate, size),
	dependency(inf_pos, growth_rate, size),
	dependency(prop_pos, size, growth_rate)]

Unfragment: []
\end{verbatim}

\subsubsection{Stacked bath tubs}

For the stacked bath tub model we changed the quantity space of flow to ZPM
(instead of ZP) because then we could replace the value-correspondences by a
single Q-correspondence.

\begin{verbatim}
Input: 
[dependency(inf_pos, flow12, level12), 
dependency(inf_pos, flow11, level11), 
dependency(inf_neg, flow12, level11), 
dependency(prop_pos, level11, flow12), 
dependency(q_correspondence, level11, flow12)]

Set of struct rels: 
[ (self, flow, flow), (self, level, level), (in, flow, level), 
(out, flow, level)]

Fragments (2): 
[ (in, flow, level), dependency(inf_pos, flow, level)]
[ (out, flow, level), 
	dependency(inf_neg, flow, level), 
	dependency(prop_pos, level, flow), 
	dependency(q_correspondence, level, flow)]

Unfragment: []
\end{verbatim}

\subsubsection{Communicating vessels} 
%both two and three? maybe also the truly compositional one?
Inducing the communicating vessels model almost works, but the last two
equalities are not found, so they have been added manually. Also, the order of
arguments for proportionalities has been tweaked. 

Two communicating vessels:

\begin{verbatim}
Input: 
[dependency(inf_pos, flow3, amount5), 
dependency(inf_neg, flow3, amount4), 
dependency(prop_neg, flow3, pressure5), 
dependency(prop_pos, flow3, pressure4), 
dependency(prop_pos, height4, amount4), 
dependency(prop_pos, height5, amount5), 
dependency(prop_pos, pressure5, height5), 
dependency(prop_pos, pressure4, height4), 
dependency(q_correspondence, height5, amount5), 
dependency(q_correspondence, pressure4, height4), 
dependency(q_correspondence, pressure5, height5), 
dependency(q_correspondence, height4, amount4), 
dependency(equals, flow3, min(pressure4, pressure5)), 
dependency(equals, height4, pressure4), 
dependency(equals, height5, pressure5)]

Set of struct rels: 
[ (self, flow, flow), (self, amount, amount), (self, amount, height), 
(self, amount, pressure), (self, height, height), (self, height, pressure),
(self, pressure, pressure), (from, amount, flow), (from, height, flow), 
(from, pressure, flow), (to, flow, amount), (to, flow, height), 
(to, flow, pressure)]

Fragments (6):
[ (self, amount, height), 
	dependency(prop_pos, height, amount), 
	dependency(q_correspondence, height, amount)]
[ (self, height, pressure), 
	dependency(prop_pos, pressure, height), 
	dependency(q_correspondence, pressure, height), 
	dependency(equals, height, pressure)]
[ (from, amount, flow), dependency(inf_neg, flow, amount)]
[ (from, pressure, flow), dependency(prop_pos, flow, pressure)]
[ (to, flow, amount), dependency(inf_pos, flow, amount)]
[ (to, flow, pressure), dependency(prop_neg, flow, pressure)]

Unfragment: [dependency(equals, flow3, min(pressure4, pressure5))]
\end{verbatim}

Three communicating vessels.

\begin{verbatim}
Input:
[dependency(inf_pos, flow3, amount5), 
dependency(inf_neg, flow3, amount4), 
dependency(prop_neg, flow3, pressure5), 
dependency(prop_pos, flow3, pressure4), 
dependency(prop_pos, height4, amount4), 
dependency(prop_pos, height5, amount5), 
dependency(prop_pos, pressure5, height5), 
dependency(prop_pos, pressure4, height4), 
dependency(q_correspondence, height5, amount5), 
dependency(q_correspondence, pressure4, height4), 
dependency(q_correspondence, pressure5, height5), 
dependency(q_correspondence, height4, amount4), 
dependency(equals, flow3, min(pressure4, pressure5)), 
dependency(equals, height4, pressure4), 
dependency(equals, height5, pressure5), 
dependency(inf_pos, flow4, amount6), 
dependency(inf_neg, flow4, amount5), 
dependency(prop_neg, flow4, pressure6), 
dependency(prop_pos, flow4, pressure5), 
dependency(prop_pos, height6, amount6), 
dependency(prop_pos, pressure6, height6), 
dependency(q_correspondence, height6, amount6), 
dependency(q_correspondence, pressure6, height6), 
dependency(equals, flow4, min(pressure5, pressure6)), 
dependency(equals, height6, pressure6)]

Set of struct rels: 
[ (self, flow, flow), (self, amount, amount), (self, amount, height), 
(self, amount, pressure), (self, height, height), (self, height, pressure),
(self, pressure, pressure), (from, amount, flow), (from, height, flow), 
(from, pressure, flow), (to, flow, amount), (to, flow, height), 
(to, flow, pressure)]

Fragments (6):
[ (self, amount, height), 
	dependency(prop_pos, height, amount), 
	dependency(q_correspondence, height, amount)]
[ (self, height, pressure), 
	dependency(prop_pos, pressure, height), 
	dependency(q_correspondence, pressure, height), 
	dependency(equals, height, pressure)]
[ (from, amount, flow), dependency(inf_neg, flow, amount)]
[ (from, pressure, flow), dependency(prop_pos, flow, pressure)]
[ (to, flow, amount), dependency(inf_pos, flow, amount)]
[ (to, flow, pressure), dependency(prop_neg, flow, pressure)]

Unfragment:
[dependency(equals, flow3, min(pressure4, pressure5)), 
dependency(equals, flow4, min(pressure5, pressure6))]
\end{verbatim}


\subsubsection{Population dynamics}
%single population? split into birth, migration etc.
%interacting populations? but ants garden is too much

\section{Discussion}

\subsection{Modular fragments as input}


\subsection{Inheritance}

\subsection{Conditions}

\subsection{Interactivity}

\subsection{Negative exemplars}

\subsection{Lift full envisionment requirement}

% World domination etc.

\section{Conclusion}

Model minimization has been fruitfully applied to Qualitative Models. Our
approach is general enough that it applies both to Automatic Modeling and to
models made by beginners.


\begin{thebibliography}{99}

% 1,5 - 2 pp. per artikel
\bibitem{newell} Allen Newell and Herbert A. Simon, “Computer Science as Empirical Inquiry: Symbols and Search,” Communications of the ACM. vol. 19, No. 3, pp. 113-126, March, 1976. \url{http://www.rci.rutgers.edu/∼cfs/472 html/AI SEARCH/PSS/PSSH1.html}

%allebei
\bibitem{bredeweg-eco} Bredeweg, B. and Salles, P. (2009), Handbook of
Ecological Modelling, Chapter 19 - Mediating conceptual knowledge using
qualitative reasoning. In: J\/orgen, S.V., Chon, T-S., Recknagel, F.A. (Eds.),
Handbook of Ecological Modelling and Informatics. Wit Press, Southampton, UK,
pp. 351.398.

%allebei
\bibitem{bredeweg-garp} Bredeweg, B., Linnebank, F., Bouwer, A. and Liem, J.
(2009) 02 Bredeweg EtAl ECOINF 2009.pdf (598.325 Kb) Garp3 - Workbench for
Qualitative Modelling and Simulation. Ecological Informatics 4(5-6), 263-281.

%hanne
\bibitem{forbus} Forbus, K.D. (1984) Qualitative process theory. Artificial 
Intelligence, 24:85-168. 

\bibitem{forbus12} Forbus, K.D. (1993) Qualitative process theory: twelve years
after. Artificial Intelligence, 59:115-123. 

%andreas
\bibitem{kleer} Kleer, J. de and Brown J.S. (1984) deKleerBrown1984.pdf (4.005
Mb) A qualitative Physics based on confluences, Artificial Intelligence,
24:7-83 (for the course you may ignore section 6)

%andreas
\bibitem{cioaca} Cioaca, Linnebank, Bredeweg, Salles 2009 Cioaca EtAlECOINF
2009.pdf (1,001.442 Kb) A qualitative reasoning model of algal bloom in the
Danube Delta Biosphere Resere (DDBR) in: ecological informatics 4 (2009)
p282-298

%hanne
\bibitem{buisman} Buisman, H., \emph{Automated modeling in process-based
qualitative reasoning}
\url{http://staff.science.uva.nl/~bredeweg/pdf/BSc/20062007/Buisman.pdf}

% (samenvatting van Buisman plus verbeteringen)
%hanne 
\bibitem{liem} Liem, J., Buisman, H. and Bredeweg, B., \emph{Supporting
Conceptual Knowledge Capture Through Automatic Modelling}

%hanne
\bibitem{vanweelden} van Weelden, C., \emph{Automated modeling of conceptual
knowledge}
\url{http://staff.science.uva.nl/~bredeweg/pdf/BSc/20082009/vanWeelden.pdf}

\end{thebibliography}

\end{document}

----------------------------------------------

Ideas

    * done: split code for model output into generation & garp adding
    * done: compositional model fragments 
    * deferred: (also: accept existing model fragments as input)
    * deferred: lift full envisionment requirement, accept negative input (eg. list of impossible value combinations).
    * deferred: user interaction: graphical dialog to choose best model in case of ambiguity

----------------------------------------------
Todos

    * done: fix influences
    * done: fix output of models to garp. deferred: each possible model should become a model fragment (too much ambiguity)
    * done: split into multiple model fragments: working code: qrsplit
    * done: collapse similar model fragments into generic model fragments (eg. Faucet1 =>I+ Bath1 and Faucet2 => I+ Bath2 becomes Faucet =>I+ Bath)
    * done: detect necessary structural relations / other conditions required to make a model fragment generic.
    * done: try other models listed in van Weelden & Buisman. notably, communicating vessels
    * distinguish between static (no influences) & process; filter current list of fragments and split them in a static and a process list.
    * integrate code with model induction (input) & garp (output)
	* input directly from AM database instead of coded by hand
	* output of minimized (split) models to garp.

    * report: 
	- Intro 
	- Summary per paper (literature review) 
	- Discussion 
	- Conclusion 
	- Project 
	- Theoretical / Practical / Technical Perspectives 
	* further details: blackboard

----------------------------------------------

Minutes
April 13th 2010

New plan:

    * Some sort of standard for what a well-formed fragment should be
    * -- Static vs process fragments?
    * -- Everything per entity 1 fragment?
    * -- Things like 'birth', 'death', 'emigration' and 'immigration'?
    * -- Influences?

    * We need some sort of evaluation to check our models against.

    * First run a the models we want to use and analyze their current output, compare them to our 'ideal' output.
    * We should not worry about intergration with the current Automatic Modeling code for now. First focus on hand-corrected input.
    * Recognizing duplicate (super)cluster could be a nice step to start with.. to get working on the code.

Notes:

    * Influences: now written to screen --> should be asserted
    * I's wrong direction? (inf-pos-a-b = b --> a)
    * naive dependencies: exponential
    * Communicating vessels: hack in causal groups: same entities (same_object_group/2)
    * Choose hacks for conceptually best model

    * Discussed with Floris that finding correspondences could be done faster by first looking for them without considering naive_dependencies yet.


----------------------------------------------

Requirements for the thesis:

 

1) The thesis consists of two parts, a literature review and a project report.

Both parts can be done in pairs or individually if this is preferred. In the
end each student should submit one integrated document. (Note that this makes
life easier: in your report you will be able to refer to concepts discussed in
the review.)

The total amount of pages should be around 30, figures included, with each part
taking about half. (Note that in general less pages may be better if all
arguments are still explicit and clear, but this is also harder in practice.
So, aim for making your points clearly and logically without unnecessary
words.)

2) The literature overview of the papers (or sections of papers) we've
discussed in class should be a scientific review, and it should show that
you've read and understood them.

A possible approach is to start with a general introduction, then summarize and
discuss each paper, and then end with a short conclusion of the papers.

The level of detail should be in between the paper itself and an abstract.
Saying state graphs are generated by a procedure is too general, listing the
steps in the procedure is too detailed. Instead give the general idea of the
procedure and discuss its properties, pros and cons.

(Hints, but not requirements: a) It is nice if you can link the papers together
in your discussion. b) It is also nice if you can use the review to introduce
the problem area of your project research. c) Note that the papers we've
discussed each have different perspectives: theoretical, technical,
application/modeling)

3) The report on your project should be like a scientific research paper and it
should be provide sufficient detail such that someone else could replicate your
work. Be sure to make all your assumptions, choices and reasoning steps
explicit.

4) If you want feedback you can submit initial versions of papers for feedback.
Allow for a couple of days for reading of course, and I will provide mainly
overall feedback on whether you're moving in the right direction or which other
approach you could take. Still this should save you time and effort, so take
the opportunity!

5) The final deadline for the thesis is Friday the 28th of May, 18:00 hours.

NB This deadline is solid as a rock, no exceptions, so evade Murphy's law and
plan in some reserve time.

Last but not least: Good Luck, Start in Time, & Have Fun!
